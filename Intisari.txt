Bahasa Inggris yang digunakan masyarakat secara global saat ini merupakan lingua franca, yaitu bahasa penyambung bagi dua pihak yang memiliki bahasa ibu berbeda. Sebagai bahasa ibu bagi lebih dari 360 juta orang dan bahasa asing bagi lebih dari 600 juta orang, Bahasa Inggris membutuhkan Mesin Penerjemah (MP) dengan kualitas tinggi dalam penerjemahan publikasi dari bahasa lain, termasuk di antaranya dari Bahasa Indonesia. Terdapat beberapa MP Bahasa Indonesia — Bahasa Inggris yang telah berkembang pada saat ini dan dapat diakses secara daring, beberapa di antaranya adalah Google Translate dan Tradukka. 
Dalam memastikan MP tersebut memiliki kualitas terjemahan yang tinggi, digunakan beberapa metode evaluasi secara otomatis oleh komputer. Tiga buah metode evaluasi otomatis yang digunakan pada penelitian ini adalah Match Accuracy (MAcc), Bilingual Evaluation Understudy (BLEU), dan Metric for Evaluation of Translation with Explicit Ordering (METEOR). Dari antara ketiga metode tersebut, dilakukan perbandingan untuk menentukan metode evaluasi otomatis terbaik dalam mengevaluasi MP. Perbandingan dilakukan menggunakan nilai Korelasi dan nilai Mean Absolut Persentase Error (MAPE) dengan didukung oleh data dari ahli bahasa.
Penelitian ini mengevaluasi hasil terjemahan kedua MP terhadap teks Referensi yang telah ditentukan sebelumnya. Lebih lanjut, nilai evaluasi yang didapatkan dari metode BLEU, MAcc, dan METEOR terhadap 150 kalimat dibandingkan menggunakan perhitungan Korelasi dan MAPE. Hasil yang didapatkan menunjukkan metode BLEU pada lingkup unigram dengan nilai mean MAPE 0.220563866 merupakan metode evaluasi otomatis terbaik dibandingkan dengan metode evaluasi otomatis MAcc dan METEOR. Hasil selanjutnya yang didapatkan menunjukkan MP Google dengan nilai MAPE lebih rendah, lebih baik dibandingkan dengan Mesin Penerjemah Tradukka pada nilai mean BLEU yang sama.
